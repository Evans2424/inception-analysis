# Additional notebook sections for Fronteiras and Metadata Analysis
# These sections should be added to the main notebook after the existing sections

# Section 8: Fronteiras Analysis
fronteiras_section = '''
   {
   "cell_type": "markdown",
   "id": "fronteiras-section",
   "metadata": {},
   "source": [
    "## 8. Fronteiras Analysis (Boundaries/Limits)\\n",
    "\\n",
    "Analysis of **fronteiras** (boundaries or limits) annotations, which represent administrative, geographical, or conceptual boundaries mentioned in municipal documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fronteiras-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fronteiras analysis\\n",
    "fronteiras_analysis = comprehensive_analysis.get('fronteiras_analysis', {})\\n",
    "\\n",
    "if 'error' not in fronteiras_analysis and fronteiras_analysis:\\n",
    "    print(\\"=== FRONTEIRAS ANALYSIS ===\\")\\n",
    "    \\n",
    "    print(f\\"\\\\nüìä Basic Statistics:\\")\\n",
    "    print(f\\"   Total fronteira entities: {fronteiras_analysis.get('total_fronteira_entities', 0):,}\\")\\n",
    "    print(f\\"   Documents with fronteira: {fronteiras_analysis.get('documents_with_fronteira', 0):,}\\")\\n",
    "    \\n",
    "    # Fronteira type distribution\\n",
    "    if 'fronteira_type_distribution' in fronteiras_analysis:\\n",
    "        fronteira_counts = fronteiras_analysis['fronteira_type_distribution']\\n",
    "        fronteira_percentages = fronteiras_analysis.get('fronteira_type_percentages', {})\\n",
    "        \\n",
    "        print(f\\"\\\\nüó∫Ô∏è Fronteira Type Distribution:\\")\\n",
    "        for fronteira_type, count in fronteira_counts.items():\\n",
    "            pct = fronteira_percentages.get(fronteira_type, 0)\\n",
    "            print(f\\"   {fronteira_type}: {count:,} ({pct:.1f}%)\\")\\n",
    "        \\n",
    "        # Create visualization\\n",
    "        fig_fronteiras = make_subplots(\\n",
    "            rows=1, cols=2,\\n",
    "            subplot_titles=('Fronteira Type Distribution', 'Fronteira by Municipality'),\\n",
    "            specs=[['pie', 'bar']]\\n",
    "        )\\n",
    "        \\n",
    "        # Pie chart for distribution\\n",
    "        fig_fronteiras.add_trace(\\n",
    "            go.Pie(\\n",
    "                labels=list(fronteira_counts.keys()),\\n",
    "                values=list(fronteira_counts.values()),\\n",
    "                name='Fronteira Distribution'\\n",
    "            ),\\n",
    "            row=1, col=1\\n",
    "        )\\n",
    "        \\n",
    "        # Bar chart by municipality (if data available)\\n",
    "        if 'fronteira_by_municipality' in fronteiras_analysis:\\n",
    "            fronteira_muni_data = fronteiras_analysis['fronteira_by_municipality']\\n",
    "            if fronteira_muni_data:\\n",
    "                # Stack fronteira types by municipality\\n",
    "                municipalities = list(fronteira_muni_data.keys())\\n",
    "                colors = px.colors.qualitative.Set1\\n",
    "                \\n",
    "                for i, fronteira_type in enumerate(fronteira_counts.keys()):\\n",
    "                    values = [fronteira_muni_data.get(muni, {}).get(fronteira_type, 0) for muni in municipalities]\\n",
    "                    fig_fronteiras.add_trace(\\n",
    "                        go.Bar(\\n",
    "                            x=municipalities,\\n",
    "                            y=values,\\n",
    "                            name=fronteira_type,\\n",
    "                            marker_color=colors[i % len(colors)]\\n",
    "                        ),\\n",
    "                        row=1, col=2\\n",
    "                    )\\n",
    "        \\n",
    "        fig_fronteiras.update_layout(\\n",
    "            title_text='üó∫Ô∏è Fronteiras (Boundaries) Analysis',\\n",
    "            height=600,\\n",
    "            barmode='stack'\\n",
    "        )\\n",
    "        \\n",
    "        fig_fronteiras.show()\\n",
    "        \\n",
    "        # Save figure\\n",
    "        fig_fronteiras.write_html(FIGURES_DIR / 'fronteiras_analysis.html')\\n",
    "        fig_fronteiras.write_image(FIGURES_DIR / 'fronteiras_analysis.png', width=1200, height=600)\\n",
    "    \\n",
    "    # Fronteira co-occurrence with entity types\\n",
    "    if 'fronteira_entity_cooccurrence' in fronteiras_analysis:\\n",
    "        cooccurrence = fronteiras_analysis['fronteira_entity_cooccurrence']\\n",
    "        \\n",
    "        print(f\\"\\\\nüîó Fronteira Co-occurrence with Entity Types:\\")\\n",
    "        for entity_type, fronteira_types in cooccurrence.items():\\n",
    "            print(f\\"   {entity_type}:\\")\\n",
    "            for fronteira_type, count in fronteira_types.items():\\n",
    "                print(f\\"     - {fronteira_type}: {count} times\\")\\n",
    "    \\n",
    "    # Text statistics for fronteira entities\\n",
    "    if 'fronteira_text_statistics' in fronteiras_analysis:\\n",
    "        text_stats = fronteiras_analysis['fronteira_text_statistics']\\n",
    "        print(f\\"\\\\nüìè Fronteira Text Statistics:\\")\\n",
    "        print(f\\"   Average length (chars): {text_stats.get('avg_length_chars', 0):.2f}\\")\\n",
    "        print(f\\"   Average length (tokens): {text_stats.get('avg_length_tokens', 0):.2f}\\")\\n",
    "    \\n",
    "    print(\\"üíæ Fronteiras analysis visualizations saved\\")\\n",
    "else:\\n",
    "    print(\\"‚ö†Ô∏è No fronteiras data available for analysis\\")\\n",
    "    if 'error' in fronteiras_analysis:\\n",
    "        print(f\\"   Error: {fronteiras_analysis['error']}\\")"\n",
   ]
  }
'''

# Section 9: Metadata Analysis
metadata_section = '''
  {
   "cell_type": "markdown",
   "id": "metadata-section",
   "metadata": {},
   "source": [
    "## 9. Metadata Analysis (Meeting Information)\\n",
    "\\n",
    "Comprehensive analysis of document metadata including meeting types, participants, presence information, political parties, and scheduling patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metadata-overview",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata analysis\\n",
    "metadata_analysis = comprehensive_analysis.get('metadata_analysis', {})\\n",
    "\\n",
    "if 'error' not in metadata_analysis and metadata_analysis:\\n",
    "    print(\\"=== METADATA ANALYSIS ===\\")\\n",
    "    \\n",
    "    # Meeting type analysis\\n",
    "    if 'meeting_type_analysis' in metadata_analysis:\\n",
    "        meeting_types = metadata_analysis['meeting_type_analysis']\\n",
    "        print(f\\"\\\\nüèõÔ∏è Meeting Type Analysis:\\")\\n",
    "        print(f\\"   Total with meeting type info: {meeting_types.get('total_with_meeting_type', 0):,}\\")\\n",
    "        \\n",
    "        types_dist = meeting_types.get('meeting_types', {})\\n",
    "        types_pct = meeting_types.get('meeting_type_percentages', {})\\n",
    "        \\n",
    "        for meeting_type, count in types_dist.items():\\n",
    "            pct = types_pct.get(meeting_type, 0)\\n",
    "            print(f\\"     {meeting_type}: {count:,} ({pct:.1f}%)\\")\\n",
    "    \\n",
    "    # Political party analysis\\n",
    "    if 'political_party_analysis' in metadata_analysis:\\n",
    "        party_analysis = metadata_analysis['political_party_analysis']\\n",
    "        print(f\\"\\\\nüèõÔ∏è Political Party Analysis:\\")\\n",
    "        print(f\\"   Total with party info: {party_analysis.get('total_with_party_info', 0):,}\\")\\n",
    "        print(f\\"   Unique parties: {party_analysis.get('unique_parties', 0)}\\")\\n",
    "        \\n",
    "        party_dist = party_analysis.get('party_distribution', {})\\n",
    "        party_pct = party_analysis.get('party_percentages', {})\\n",
    "        \\n",
    "        print(f\\"\\\\n   Top Political Parties:\\")\\n",
    "        for party, count in sorted(party_dist.items(), key=lambda x: x[1], reverse=True)[:10]:\\n",
    "            pct = party_pct.get(party, 0)\\n",
    "            print(f\\"     {party}: {count:,} ({pct:.1f}%)\\")\\n",
    "        \\n",
    "        # Party by municipality visualization\\n",
    "        if 'party_by_municipality' in party_analysis:\\n",
    "            party_muni_data = party_analysis['party_by_municipality']\\n",
    "            \\n",
    "            # Create heatmap for party-municipality distribution\\n",
    "            if party_muni_data:\\n",
    "                party_muni_df = pd.DataFrame(party_muni_data).fillna(0)\\n",
    "                \\n",
    "                fig_party_heatmap = px.imshow(\\n",
    "                    party_muni_df.values,\\n",
    "                    x=party_muni_df.columns,\\n",
    "                    y=party_muni_df.index,\\n",
    "                    title='üó≥Ô∏è Political Party Distribution by Municipality',\\n",
    "                    labels={'x': 'Political Party', 'y': 'Municipality', 'color': 'Count'},\\n",
    "                    aspect='auto',\\n",
    "                    color_continuous_scale='Reds'\\n",
    "                )\\n",
    "                \\n",
    "                fig_party_heatmap.update_layout(height=600)\\n",
    "                fig_party_heatmap.show()\\n",
    "                \\n",
    "                fig_party_heatmap.write_html(FIGURES_DIR / 'political_party_by_municipality.html')\\n",
    "    \\n",
    "    # Presence analysis\\n",
    "    if 'presence_analysis' in metadata_analysis:\\n",
    "        presence_analysis = metadata_analysis['presence_analysis']\\n",
    "        print(f\\"\\\\nüë• Presence Analysis:\\")\\n",
    "        print(f\\"   Total with presence info: {presence_analysis.get('total_with_presence_info', 0):,}\\")\\n",
    "        \\n",
    "        presence_types = presence_analysis.get('presence_types', {})\\n",
    "        presence_pct = presence_analysis.get('presence_percentages', {})\\n",
    "        \\n",
    "        for presence_type, count in presence_types.items():\\n",
    "            pct = presence_pct.get(presence_type, 0)\\n",
    "            print(f\\"     {presence_type}: {count:,} ({pct:.1f}%)\\")\\n",
    "    \\n",
    "    # Schedule analysis\\n",
    "    if 'schedule_analysis' in metadata_analysis:\\n",
    "        schedule_analysis = metadata_analysis['schedule_analysis']\\n",
    "        print(f\\"\\\\nüïí Schedule Analysis:\\")\\n",
    "        print(f\\"   Total with schedule info: {schedule_analysis.get('total_with_schedule', 0):,}\\")\\n",
    "        print(f\\"   Documents with schedule: {schedule_analysis.get('documents_with_schedule', 0):,}\\")\\n",
    "        \\n",
    "        schedule_patterns = schedule_analysis.get('schedule_patterns', {})\\n",
    "        if schedule_patterns:\\n",
    "            print(f\\"\\\\n   Most Common Schedule Patterns:\\")\\n",
    "            for schedule, count in list(schedule_patterns.items())[:10]:\\n",
    "                print(f\\"     {schedule}: {count} times\\")\\n",
    "    \\n",
    "    print(\\"üíæ Metadata analysis completed\\")\\n",
    "else:\\n",
    "    print(\\"‚ö†Ô∏è No metadata available for analysis\\")\\n",
    "    if 'error' in metadata_analysis:\\n",
    "        print(f\\"   Error: {metadata_analysis['error']}\\")"\n",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metadata-correlations",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata correlations analysis\\n",
    "if 'metadata_correlations' in metadata_analysis:\\n",
    "    correlations = metadata_analysis['metadata_correlations']\\n",
    "    \\n",
    "    print(\\"\\\\n=== METADATA CORRELATIONS ===\\")\\n",
    "    print(\\"Cross-tabulation analysis of metadata fields:\\\\n\\")\\n",
    "    \\n",
    "    # Create visualizations for key correlations\\n",
    "    fig_correlations = make_subplots(\\n",
    "        rows=2, cols=2,\\n",
    "        subplot_titles=list(correlations.keys())[:4],\\n",
    "        specs=[['heatmap', 'heatmap'], ['heatmap', 'heatmap']]\\n",
    "    )\\n",
    "    \\n",
    "    correlation_data = list(correlations.items())[:4]  # Show first 4 correlations\\n",
    "    \\n",
    "    positions = [(1, 1), (1, 2), (2, 1), (2, 2)]\\n",
    "    \\n",
    "    for i, (corr_name, corr_data) in enumerate(correlation_data):\\n",
    "        if i < 4:\\n",
    "            # Convert to DataFrame for visualization\\n",
    "            corr_df = pd.DataFrame(corr_data).fillna(0)\\n",
    "            \\n",
    "            row, col = positions[i]\\n",
    "            \\n",
    "            fig_correlations.add_trace(\\n",
    "                go.Heatmap(\\n",
    "                    z=corr_df.values,\\n",
    "                    x=corr_df.columns,\\n",
    "                    y=corr_df.index,\\n",
    "                    colorscale='Blues',\\n",
    "                    showscale=True if i == 0 else False\\n",
    "                ),\\n",
    "                row=row, col=col\\n",
    "            )\\n",
    "            \\n",
    "            print(f\\"{corr_name}:\\")\\n",
    "            print(corr_df)\\n",
    "            print()\\n",
    "    \\n",
    "    fig_correlations.update_layout(\\n",
    "        title_text='üîó Metadata Cross-Correlations',\\n",
    "        height=800\\n",
    "    )\\n",
    "    \\n",
    "    fig_correlations.show()\\n",
    "    \\n",
    "    # Save figure\\n",
    "    fig_correlations.write_html(FIGURES_DIR / 'metadata_correlations.html')\\n",
    "    \\n",
    "    print(\\"üíæ Metadata correlations visualization saved\\")"\n",
   ]
  }
'''

print("Additional sections created for Fronteiras and Metadata analysis")
print("These should be inserted into the main notebook between sections 7 and 8")
print("The sections include:")
print("- Fronteiras (boundaries) type distribution and co-occurrence analysis")
print("- Political party analysis with cross-municipality patterns") 
print("- Meeting type, presence, and schedule pattern analysis")
print("- Metadata correlations with heatmap visualizations")